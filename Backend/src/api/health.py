"""
Endpoint-uri pentru verificarea stÄƒrii aplicaÈ›iei È™i monitorizare.
"""

from fastapi import APIRouter, HTTPException
from typing import Dict, Any
import torch
import psutil
import time
from datetime import datetime

from src.core import settings, logger, get_logger
from src.utils import get_directory_stats, cleanup_old_files

# Router pentru endpoint-urile de health
router = APIRouter(prefix="/api/health", tags=["Health & Monitoring"])
health_logger = get_logger("api.health")


@router.get("/", summary="Health check basic")
async def health_check() -> Dict[str, Any]:
    """
    Verificare de bazÄƒ a stÄƒrii aplicaÈ›iei.

    Returns:
        Status general al aplicaÈ›iei
    """
    health_logger.info("â¤ï¸ Health check executat")

    try:
        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "app": settings.app_name,
            "version": settings.app_version,
            "message": "API funcÈ›ioneazÄƒ normal"
        }
    except Exception as e:
        health_logger.error(f"âŒ Eroare la health check: {e}")
        raise HTTPException(status_code=500, detail=f"Health check failed: {e}")


@router.get("/detailed", summary="Health check detaliat")
async def detailed_health_check() -> Dict[str, Any]:
    """
    Verificare detaliatÄƒ a tuturor componentelor sistemului.

    Returns:
        Status detaliat al tuturor componentelor
    """
    health_logger.info("ğŸ” Health check detaliat executat")

    try:
        # VerificÄƒ PyTorch È™i GPU
        torch_info = {
            "available": True,
            "version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "device": settings.model_device
        }

        if torch.cuda.is_available():
            torch_info.update({
                "cuda_version": torch.version.cuda,
                "gpu_count": torch.cuda.device_count(),
                "current_device": torch.cuda.current_device(),
                "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else None
            })

        # VerificÄƒ directoarele È™i storage
        directory_stats = get_directory_stats()

        # InformaÈ›ii sistem
        system_info = {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_usage": psutil.disk_usage('/').percent if psutil.disk_usage('/') else None,
            "uptime_seconds": time.time() - psutil.boot_time()
        }

        # VerificÄƒ configurÄƒrile critice
        config_status = {
            "upload_dir_writable": True,  # Verificat prin directory_stats
            "output_dir_writable": True,
            "model_path_configured": bool(settings.model_path),
            "max_file_size_mb": settings.max_file_size // (1024 * 1024),
            "allowed_extensions": settings.allowed_extensions
        }

        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "app_info": {
                "name": settings.app_name,
                "version": settings.app_version,
                "debug": settings.debug
            },
            "pytorch": torch_info,
            "directories": directory_stats,
            "system": system_info,
            "configuration": config_status
        }

    except Exception as e:
        health_logger.error(f"âŒ Eroare la health check detaliat: {e}")
        raise HTTPException(status_code=500, detail=f"Detailed health check failed: {e}")


@router.get("/stats", summary="Statistici aplicaÈ›ie")
async def get_app_stats() -> Dict[str, Any]:
    """
    ReturneazÄƒ statistici despre utilizarea aplicaÈ›iei.

    Returns:
        Statistici despre fiÈ™iere, directoare È™i performanÈ›Äƒ
    """
    health_logger.info("ğŸ“Š Statistici aplicaÈ›ie solicitate")

    try:
        # Statistici directoare
        directory_stats = get_directory_stats()

        # Statistici sistem
        memory = psutil.virtual_memory()
        cpu_stats = {
            "cpu_count": psutil.cpu_count(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "load_average": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
        }

        memory_stats = {
            "total_gb": round(memory.total / (1024 ** 3), 2),
            "available_gb": round(memory.available / (1024 ** 3), 2),
            "used_gb": round(memory.used / (1024 ** 3), 2),
            "percent": memory.percent
        }

        # InformaÈ›ii PyTorch
        pytorch_stats = {
            "version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "device": settings.model_device
        }

        if torch.cuda.is_available():
            pytorch_stats["gpu_memory_allocated"] = torch.cuda.memory_allocated()
            pytorch_stats["gpu_memory_cached"] = torch.cuda.memory_reserved()

        return {
            "timestamp": datetime.utcnow().isoformat(),
            "directories": directory_stats,
            "cpu": cpu_stats,
            "memory": memory_stats,
            "pytorch": pytorch_stats,
            "configuration": {
                "max_file_size_mb": settings.max_file_size // (1024 * 1024),
                "allowed_extensions": settings.allowed_extensions,
                "model_device": settings.model_device
            }
        }

    except Exception as e:
        health_logger.error(f"âŒ Eroare la obÈ›inerea statisticilor: {e}")
        raise HTTPException(status_code=500, detail=f"Stats retrieval failed: {e}")


@router.post("/cleanup", summary="CurÄƒÈ›Äƒ fiÈ™ierele vechi")
async def cleanup_files(max_age_hours: int = 24) -> Dict[str, Any]:
    """
    È˜terge fiÈ™ierele mai vechi de un numÄƒr specificat de ore.

    Args:
        max_age_hours: VÃ¢rsta maximÄƒ Ã®n ore (default: 24)

    Returns:
        NumÄƒrul de fiÈ™iere È™terse din fiecare director
    """
    health_logger.info(f"ğŸ§¹ Cleanup solicit cu max_age_hours={max_age_hours}")

    if max_age_hours < 1:
        raise HTTPException(status_code=400, detail="max_age_hours trebuie sÄƒ fie cel puÈ›in 1")

    try:
        deleted_counts = cleanup_old_files(max_age_hours)

        health_logger.info(f"âœ… Cleanup finalizat: {deleted_counts}")

        return {
            "message": "Cleanup executat cu succes",
            "max_age_hours": max_age_hours,
            "files_deleted": deleted_counts,
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        health_logger.error(f"âŒ Eroare la cleanup: {e}")
        raise HTTPException(status_code=500, detail=f"Cleanup failed: {e}")


@router.get("/ready", summary="Readiness probe")
async def readiness_probe() -> Dict[str, Any]:
    """
    Endpoint pentru Kubernetes readiness probe.
    VerificÄƒ cÄƒ aplicaÈ›ia este gata sÄƒ primeascÄƒ trafic.

    Returns:
        Status de readiness
    """
    try:
        # VerificÄƒri critice pentru readiness
        checks = {
            "pytorch_available": torch.cuda.is_available() or settings.model_device == "cpu",
            "directories_accessible": True,  # Verificat prin directory_stats
            "configuration_valid": bool(settings.model_path)
        }

        # TesteazÄƒ accesul la directoare
        try:
            get_directory_stats()
            checks["directories_accessible"] = True
        except Exception:
            checks["directories_accessible"] = False

        all_ready = all(checks.values())

        return {
            "ready": all_ready,
            "checks": checks,
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        health_logger.error(f"âŒ Eroare la readiness probe: {e}")
        raise HTTPException(status_code=503, detail=f"Not ready: {e}")


@router.get("/live", summary="Liveness probe")
async def liveness_probe() -> Dict[str, Any]:
    """
    Endpoint pentru Kubernetes liveness probe.
    VerificÄƒ cÄƒ aplicaÈ›ia ruleazÄƒ È™i poate rÄƒspunde.

    Returns:
        Status de liveness
    """
    return {
        "alive": True,
        "timestamp": datetime.utcnow().isoformat(),
        "app": settings.app_name
    }